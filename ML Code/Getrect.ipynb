{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-27T08:59:36.066484Z","iopub.execute_input":"2023-09-27T08:59:36.066844Z","iopub.status.idle":"2023-09-27T08:59:37.329069Z","shell.execute_reply.started":"2023-09-27T08:59:36.066814Z","shell.execute_reply":"2023-09-27T08:59:37.328082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense,Flatten,Dropout,BatchNormalization\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nimport cv2 as cv\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport albumentations as A\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-09-27T08:59:38.579677Z","iopub.execute_input":"2023-09-27T08:59:38.58018Z","iopub.status.idle":"2023-09-27T08:59:52.587177Z","shell.execute_reply.started":"2023-09-27T08:59:38.580148Z","shell.execute_reply":"2023-09-27T08:59:52.586093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_base = ResNet50(\n    weights = 'imagenet',\n    include_top = False, #Means we are excluding the top FC layers of our model\n    input_shape = (224,224,3)\n)  \n# conv_base.summary()    \nconv_base.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-09-27T08:54:06.250968Z","iopub.execute_input":"2023-09-27T08:54:06.251996Z","iopub.status.idle":"2023-09-27T08:54:14.49672Z","shell.execute_reply.started":"2023-09-27T08:54:06.251959Z","shell.execute_reply":"2023-09-27T08:54:14.495726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.8))\nmodel.add(Dense(4,activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-27T08:54:14.499542Z","iopub.execute_input":"2023-09-27T08:54:14.49993Z","iopub.status.idle":"2023-09-27T08:54:15.059151Z","shell.execute_reply.started":"2023-09-27T08:54:14.499896Z","shell.execute_reply":"2023-09-27T08:54:15.058198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n#     A.Resize(224, 224), \n    A.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n    )\n])\n\n\nlabels = ['grassy','rocky','sandy','marshy']\nlabels_OHE = {'grassy': np.array([1.,0.,0.,0.]),'rocky': np.array([0.,1.,0.,0.]),'sandy': np.array([0.,0.,1.,0.]),'marshy': np.array([0.,0.,0.,1.])}\nroot = '/kaggle/input/'\nclass Dataset:\n    def __init__(self, path):\n        self.path = path\n        self.targets = []\n        self.images = []\n        self.labels = labels\n        for label in self.labels:\n            goto = path + label + '/' +label\n            if(label == 'grassy'):\n                goto = path + label  + '/' +label[:-1]\n            for i in os.listdir(goto):\n                self.targets.append(labels_OHE[label])\n                img = cv.imread(goto +'/'+i)\n                # print(label+'/'+i)\n                # img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n                # cv2_imshow(img)\n                h,w = img.shape[:2]\n                H,W = 0,0\n                if h<w:\n                    H = 224\n                    W = int(224*w/h)\n                    img = cv.resize(img,[W,H])\n                    img = img[:,int(W/2-112):int(W/2+112),:]\n                else:\n                    W = 224\n                    H = int(224*h/w)\n                    img = cv.resize(img,[W,H])\n                    img = img[H-W:H,:,:]\n#                 print(img.shape, h,w)\n#                 print(goto +'/'+i)\n                \n                img = transform(image = img)\n#                 print(img)\n#                 img = np.resize(img, [224,224,3])\n\n                self.images.append(img['image'])\n    def __len__(self):\n        return len(self.targets)\n    def __getitem__(self,idx):\n        return {self.images[idx]:self.targets[idx]}\n    def get_XY(self):\n        return self.images, self.targets\n\nmySet = Dataset(root)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:02:43.140811Z","iopub.execute_input":"2023-09-27T09:02:43.141853Z","iopub.status.idle":"2023-09-27T09:03:14.631111Z","shell.execute_reply.started":"2023-09-27T09:02:43.141818Z","shell.execute_reply":"2023-09-27T09:03:14.629973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X , y = mySet.get_XY()\ngrass = \"/content/drive/MyDrive/SIH 2023/grassy\"\nrock = \"/content/drive/MyDrive/SIH 2023/rocky\"\nsand = \"/content/drive/MyDrive/SIH 2023/sandy\"\nmarsh = \"/content/drive/MyDrive/SIH 2023/marshy\"\n\n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    samplewise_center=True,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=20,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.2,\n    zoom_range=0.2,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=True,\n    vertical_flip=False,\n    rescale=1/255.,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split=0.3,\n    interpolation_order=1,\n    dtype=None\n)\ndatagen.fit(X)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:03:14.633159Z","iopub.execute_input":"2023-09-27T09:03:14.633537Z","iopub.status.idle":"2023-09-27T09:03:23.221264Z","shell.execute_reply.started":"2023-09-27T09:03:14.633502Z","shell.execute_reply":"2023-09-27T09:03:23.22012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_weights()\n# train_data = mySet\n# train_loader = DataLoader(dataset=train_data,batch_size=4,shuffle=True)\nmodel.compile(\n    optimizer = keras.optimizers.Adam(learning_rate = 0.001,weight_decay = 0.05),\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\n\n# model.fit(np.array(X),np.array(y),batch_size = 32,epochs = 1,validation_split = 0.2)\n# iterator = datagen.flow(X,y)\n# model.fit(datagen.flow(np.array(X), y, batch_size=32, subset = 'training'))\n\n\n\n# model.predict(datagen.flow(np.array(X), y,\n#          batch_size=1, subset='validation'))","metadata":{"execution":{"iopub.status.busy":"2023-09-27T08:54:56.634329Z","iopub.execute_input":"2023-09-27T08:54:56.634771Z","iopub.status.idle":"2023-09-27T08:55:42.587066Z","shell.execute_reply.started":"2023-09-27T08:54:56.634734Z","shell.execute_reply":"2023-09-27T08:55:42.585936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nmodel.fit(datagen.flow(np.array(X), y, batch_size=32,\n         subset='training'),\n         validation_data=datagen.flow(np.array(X), y,\n         batch_size=8, subset='validation'),\n         steps_per_epoch=len(X) / 40, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:05:22.881774Z","iopub.execute_input":"2023-09-27T09:05:22.882576Z","iopub.status.idle":"2023-09-27T09:06:13.547511Z","shell.execute_reply.started":"2023-09-27T09:05:22.882534Z","shell.execute_reply":"2023-09-27T09:06:13.546141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:07:14.378012Z","iopub.execute_input":"2023-09-27T09:07:14.379126Z","iopub.status.idle":"2023-09-27T09:07:16.317623Z","shell.execute_reply.started":"2023-09-27T09:07:14.379086Z","shell.execute_reply":"2023-09-27T09:07:16.316451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.predict(datagen.flow(np.array(X), y,\n         batch_size=1, subset='validation'))*100","metadata":{"execution":{"iopub.status.busy":"2023-09-27T09:07:59.705019Z","iopub.execute_input":"2023-09-27T09:07:59.705418Z","iopub.status.idle":"2023-09-27T09:08:08.505082Z","shell.execute_reply.started":"2023-09-27T09:07:59.70539Z","shell.execute_reply":"2023-09-27T09:08:08.503948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
